{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d3757ba",
   "metadata": {},
   "source": [
    "# Part 1 - Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deeac3dd",
   "metadata": {},
   "source": [
    "Task 1.1 Data preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "f5c33ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC03\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import os\n",
    "\n",
    "df1 = pd.read_csv('AlgerianFF_Region1.csv')\n",
    "cwd = os.getcwd()\n",
    "print(cwd)\n",
    "\n",
    "print (df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf8d090",
   "metadata": {},
   "source": [
    "Splitting data for dataset into inputs & targets for Dataset 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "b13f3752",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_inputs = df1.values[:,:-1].astype(float)\n",
    "df1_targets = df1.values[:,-1].astype(float)\n",
    "print(df1_inputs, df1_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "88a8c5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df2 = pd.read_csv ('AlgerianFF_Region2.csv')\n",
    "print (df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73b12a2",
   "metadata": {},
   "source": [
    "Splitting data for dataset into inputs & targets for Dataset 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a58b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Second Dataset \\n\")\n",
    "df2_inputs = df2.values[:,:-1].astype(float)\n",
    "df2_targets = df2.values[:,-1].astype(float)\n",
    "print(df1_inputs, df1_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "650b131a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine df1 (dataset1) with df2 (dataset2)\n",
    "output_data = df1.append(df2)\n",
    "print(output_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73da125f",
   "metadata": {},
   "source": [
    "Noramlization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9a283e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "df1_inputs = preprocessing.normalize(df1_inputs)\n",
    "print(df1_inputs)\n",
    "\n",
    "\n",
    "#Scale the inputs\n",
    "scaler = MinMaxScaler()\n",
    "scaled = scaler.fit_transform(df1_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72b3981",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_inputs = preprocessing.normalize(df2_inputs)\n",
    "print(df1_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d02210",
   "metadata": {},
   "source": [
    "Task 1.2 Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d35ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d03ae63",
   "metadata": {},
   "source": [
    "a) Creation of regression tool for MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2c4e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "7e2d4886",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor1 = MLPRegressor(solver='lbfgs', max_iter=4000)\n",
    "regressor1.fit(df1, df1_targets)\n",
    "outputs = regressor1.predict(df1)\n",
    "print(\"Mean absolute error: \", mean_absolute_error(df1_targets, outputs))\n",
    "\n",
    "#calculate MAE\n",
    "REG1_mae = abs(cross_val_score(regressor1, df1_inputs, df1_targets, scoring=\"neg_mean_absolute_error\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e677226",
   "metadata": {},
   "source": [
    "b) Creation of regression tool for SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2da795",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVRregressor = SVR()\n",
    "SVRregressor.fit(df1_inputs, df1_targets)\n",
    "SVRoutputs = SVRregressor.predict(df1_inputs)\n",
    "\n",
    "print(\"Mean absolute error: \", mean_absolute_error(df1_targets, SVRoutputs))\n",
    "\n",
    "#calculate MAE\n",
    "RFreg_mae = abs(cross_val_score(SVRregressor, df1_inputs, df1_targets, scoring=\"neg_mean_absolute_error\")) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2572b4c",
   "metadata": {},
   "source": [
    "c) Creation of regressor tool for RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc52150a",
   "metadata": {},
   "outputs": [],
   "source": [
    "RandFor_Regressor = RandomForestRegressor()\n",
    "RandFor_Regressor.fit(df1_inputs, df1_targets)\n",
    "outputs =  RandFor_Regressor.predict(df1_inputs)\n",
    "\n",
    "print(\"Mean absolute error: \", mean_absolute_error(df1_targets, outputs))\n",
    "\n",
    "#calculate MAE\n",
    "RandREG_mae = abs(cross_val_score(RandFor_Regressor, df1_inputs, df1_targets, scoring=\"neg_mean_absolute_error\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c211b0d7",
   "metadata": {},
   "source": [
    "Task 1.3 Assessment of regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd882bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store mae results into a python array \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "maeArray = [REG1_mae, RFreg_mae, RandREG_mae]\n",
    "\n",
    "REG1 = np.random.rand(100)\n",
    "REG2 = np.random.randn(100)\n",
    "REG3 = np.random.rand(100)\n",
    "\n",
    "plt.figure()\n",
    "plt.boxplot([REG1_mae, RFreg_mae, RandREG_mae])\n",
    "plt.xticks([1,2,3], [\"MLPRegressor\", \"SVRRegressor\", \"RandomForestRegressor\"]);\n",
    "plt.ylabel(\"$p(x)$\")\n",
    "plt.savefig(\"boxplot.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f185c517",
   "metadata": {},
   "source": [
    "# PART 2 – EVOLUTIONARY COMPUTATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183198bb",
   "metadata": {},
   "source": [
    "Task 2.1 –Generation of random solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6e06db",
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = pd.read_csv(r'distances.csv', header=None)\n",
    "print (distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a897e6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = open(r'cities.txt')\n",
    "test = cities.read().splitlines()\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bae06eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "# dislaying distances\n",
    "\n",
    "def randRoute(distances):\n",
    "    route = list(range(len(distances)))\n",
    "    #shuffeling cities\n",
    "    random.shuffle(route)\n",
    "    return route\n",
    "print(randRoute(distances)) # creating a random route\n",
    "\n",
    "\n",
    "#working out length of route\n",
    "\n",
    "def route_length(route, dist):\n",
    "    length = 0 #sets the varaible 'length' to zero\n",
    "    for i in range(len(route)): # looks through the array\n",
    "       length += dist.iat[route[i-1], route[i]] # for how many cities are in the route, get distance of first city and next city\n",
    "    \n",
    "    return length\n",
    "\n",
    "x = randRoute(distances)\n",
    "y = route_length(x, distances)\n",
    "print(x)\n",
    "print(y)\n",
    "#x = randRoute(distances)\n",
    "#print (x)\n",
    "#y = route_length(x, distances)\n",
    "#print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e723e77",
   "metadata": {},
   "source": [
    "Task 2.2 –Algorithm implementation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72919280",
   "metadata": {},
   "source": [
    "2.2.1 - Creation of Ruin and Recreate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11fecd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ruinAndRecreate(iterations):\n",
    "    \n",
    "    RandList = []\n",
    "    \n",
    "    bestRoute = randRoute(distances)\n",
    "    bestRouteLength = route_length(bestRoute, distances)\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        route2 = randRoute(distances)\n",
    "        print(route2)\n",
    "        routelength2 = route_length(route2, distances)\n",
    "        if routelength2 < bestRouteLength:\n",
    "            bestRouteLength = routelength2\n",
    "            bestRoute = route2\n",
    "        RandList.append(bestRouteLength) #iterates through and generates a new route , if it was better than previous routes it becomes the best route is kept till the next iteration \n",
    "    return RandList\n",
    "print(ruinAndRecreate(30))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3318f5f",
   "metadata": {},
   "source": [
    "2.2.1 - Creation of swap function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5986496f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def swap(iterations):\n",
    "    print(\"swap Function\") # for readability\n",
    "    \n",
    "    SwapList = []\n",
    "    \n",
    "    bestRoute = randRoute(distances)\n",
    "    bestRouteLength = route_length(bestRoute, distances)\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        newRoute = bestRoute.copy() # copies the values of bestRoute\n",
    "        newRouteLength = route_length(newRoute, distances) #records the length of the new route, and gives something to compare what route is more fitter out of the bestroute and newroute\n",
    "        \n",
    "        print(\"Best route = \", bestRoute, \": Length = \", bestRouteLength) # make sure it works\n",
    "        \n",
    "        newRoutePosition1 = random.randint(0, max(newRoute))\n",
    "        newRoutePosition2 = random.randint(0, max(newRoute))\n",
    "        \n",
    "        \n",
    "        newRoute[newRoutePosition1], newRoute[newRoutePosition2] = newRoute[newRoutePosition2], newRoute[newRoutePosition1]\n",
    "        print(\"New Route = \", newRoute, \": Length = \", newRouteLength)\n",
    "        newRouteLength = route_length(newRoute, distances)\n",
    "        \n",
    "        if(bestRouteLength > newRouteLength):\n",
    "            bestRoute = newRoute\n",
    "            bestRouteLength = newRouteLength\n",
    "        else:\n",
    "            bestRoute = bestRoute\n",
    "            bestRouteLength = bestRouteLength\n",
    "        SwapList.append(bestRouteLength)\n",
    "        print(\"Best Route = \", bestRoute, \": Length = \", bestRouteLength)\n",
    "        \n",
    "    print(\"Best Route = \", route_length(bestRoute, distances))\n",
    "        \n",
    "    \n",
    "    return SwapList\n",
    "\n",
    "print(swap(30))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ced077",
   "metadata": {},
   "source": [
    "Task 2.3 – Visualisation of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334effba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "def results():\n",
    "    SwapList = []\n",
    "    RuinNRecreateList = []\n",
    "    \n",
    "    for i in range(30):\n",
    "        SwapList.append(swap(30))\n",
    "        RuinNRecreateList.append(ruinAndRecreate(30))\n",
    "        \n",
    "        # turning both lists into numpy arrays because it works out max , min and average calculations\n",
    "        Array1 = numpy.array(SwapList) \n",
    "        Array2 = numpy.array(RuinNRecreateList)\n",
    "\n",
    "    plt.plot(Array1.min(axis=0))\n",
    "    plt.plot(Array1.max(axis=0))\n",
    "    plt.plot(Array1.mean(axis=0))\n",
    "    \n",
    "    plt.plot(Array2.min(axis=0))\n",
    "    plt.plot(Array2.max(axis=0))\n",
    "    plt.plot(Array2.mean(axis=0))\n",
    "    plt.legend([\"Swap mutation minimum\",\"Swap mutation maximum\", \"Swap mutation mean\", \"Ruin and Recreate minimum\", \"Ruin and Recreate maximum\", \"Ruin and Recreate mean\"], loc=(1,0.5))\n",
    "    plt.show()\n",
    "    \n",
    "results()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69bd6696",
   "metadata": {},
   "source": [
    "The best mutation operator for the traveling saleman problem is the swap function because on the graph the mean value is seen traveling downwards at a faster and more reliable rate , where as the Ruin and recreate is slower. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
